{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYo63MEYlnX0DZeYo7uOzZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DinushaSa/Pytorchvis/blob/main/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSfpV94LnvJk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCWld71Kn5cg"
      },
      "source": [
        "def atoi(s):\n",
        "    n = 0\n",
        "    for i in s:\n",
        "        n = n*10 + ord(i) - ord(\"0\")\n",
        "    return n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC68_vInn-2z"
      },
      "source": [
        "outer_names = ['test','train']\n",
        "inner_names = ['angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral']\n",
        "os.makedirs('data', exist_ok=True)\n",
        "for outer_name in outer_names:\n",
        "    os.makedirs(os.path.join('data',outer_name), exist_ok=True)\n",
        "    for inner_name in inner_names:\n",
        "        os.makedirs(os.path.join('data',outer_name,inner_name), exist_ok=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt_fl5uJoEVG"
      },
      "source": [
        "angry = 0\n",
        "disgusted = 0\n",
        "fearful = 0\n",
        "happy = 0\n",
        "sad = 0\n",
        "surprised = 0\n",
        "neutral = 0\n",
        "angry_test = 0\n",
        "disgusted_test = 0\n",
        "fearful_test = 0\n",
        "happy_test = 0\n",
        "sad_test = 0\n",
        "surprised_test = 0\n",
        "neutral_test = 0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu5uHM-UoJJJ",
        "outputId": "2b286916-fd41-4eb9-b9f6-72224a72cc2f"
      },
      "source": [
        "!pip install opendatasets --upgrade --quiet\n",
        "import opendatasets as od\n",
        "\n",
        "dataset_url = 'https://www.kaggle.com/deadskull7/fer2013'\n",
        "DATA_FILENAME = \"fer.csv\"\n",
        "od.download(dataset_url, '.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: angiyoangiyo\n",
            "Your Kaggle Key: ··········\n",
            "Downloading fer2013.zip to ./fer2013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 96.6M/96.6M [00:00<00:00, 166MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8XtItKIoYqq"
      },
      "source": [
        "DATA_FILENAME = \"fer2013.csv\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F1Z3-yTogRI"
      },
      "source": [
        "DATA_DIR = './fer2013/fer2013.csv'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Ozj-wcBNohyd",
        "outputId": "5e7904e7-93e6-43c5-f126-3bb0c07985d4"
      },
      "source": [
        "df = pd.read_csv(DATA_DIR)\n",
        "df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35882</th>\n",
              "      <td>6</td>\n",
              "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35883</th>\n",
              "      <td>3</td>\n",
              "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35884</th>\n",
              "      <td>0</td>\n",
              "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35885</th>\n",
              "      <td>3</td>\n",
              "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35886</th>\n",
              "      <td>2</td>\n",
              "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35887 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion                                             pixels        Usage\n",
              "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
              "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
              "2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n",
              "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n",
              "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n",
              "...        ...                                                ...          ...\n",
              "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
              "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
              "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
              "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
              "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
              "\n",
              "[35887 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy66JqjporbN",
        "outputId": "fcd0028b-e758-4556-9ad2-63d186dd7a2c"
      },
      "source": [
        "mat = np.zeros((48,48),dtype=np.uint8)\n",
        "print(\"Saving images...\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving images...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGZuXz_XotOi",
        "outputId": "e4d9a123-66ba-4540-8266-4bfe2c873359"
      },
      "source": [
        "for i in tqdm(range(len(df))):\n",
        "    txt = df['pixels'][i]\n",
        "    words = txt.split()\n",
        "    \n",
        "    # the image size is 48x48\n",
        "    for j in range(2304):\n",
        "        xind = j // 48\n",
        "        yind = j % 48\n",
        "        mat[xind][yind] = atoi(words[j])\n",
        "\n",
        "    img = Image.fromarray(mat)\n",
        "\n",
        "    # train\n",
        "    if i < 28709:\n",
        "        if df['emotion'][i] == 0:\n",
        "            img.save('data/train/angry/im'+str(angry)+'.png')\n",
        "            angry += 1\n",
        "        elif df['emotion'][i] == 1:\n",
        "            img.save('data/train/disgusted/im'+str(disgusted)+'.png')\n",
        "            disgusted += 1\n",
        "        elif df['emotion'][i] == 2:\n",
        "            img.save('data/train/fearful/im'+str(fearful)+'.png')\n",
        "            fearful += 1\n",
        "        elif df['emotion'][i] == 3:\n",
        "            img.save('data/train/happy/im'+str(happy)+'.png')\n",
        "            happy += 1\n",
        "        elif df['emotion'][i] == 4:\n",
        "            img.save('data/train/sad/im'+str(sad)+'.png')\n",
        "            sad += 1\n",
        "        elif df['emotion'][i] == 5:\n",
        "            img.save('data/train/surprised/im'+str(surprised)+'.png')\n",
        "            surprised += 1\n",
        "        elif df['emotion'][i] == 6:\n",
        "            img.save('data/train/neutral/im'+str(neutral)+'.png')\n",
        "            neutral += 1\n",
        "\n",
        "    # test\n",
        "    else:\n",
        "        if df['emotion'][i] == 0:\n",
        "            img.save('data/test/angry/im'+str(angry_test)+'.png')\n",
        "            angry_test += 1\n",
        "        elif df['emotion'][i] == 1:\n",
        "            img.save('data/test/disgusted/im'+str(disgusted_test)+'.png')\n",
        "            disgusted_test += 1\n",
        "        elif df['emotion'][i] == 2:\n",
        "            img.save('data/test/fearful/im'+str(fearful_test)+'.png')\n",
        "            fearful_test += 1\n",
        "        elif df['emotion'][i] == 3:\n",
        "            img.save('data/test/happy/im'+str(happy_test)+'.png')\n",
        "            happy_test += 1\n",
        "        elif df['emotion'][i] == 4:\n",
        "            img.save('data/test/sad/im'+str(sad_test)+'.png')\n",
        "            sad_test += 1\n",
        "        elif df['emotion'][i] == 5:\n",
        "            img.save('data/test/surprised/im'+str(surprised_test)+'.png')\n",
        "            surprised_test += 1\n",
        "        elif df['emotion'][i] == 6:\n",
        "            img.save('data/test/neutral/im'+str(neutral_test)+'.png')\n",
        "            neutral_test += 1\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35887/35887 [02:14<00:00, 267.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPorEPwyqrXJ"
      },
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnDyCKpaq8q1"
      },
      "source": [
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"--mode\",help=\"data/train/display\")\n",
        "ap.add_argument(\"-f\", \"--file\", required=False) \n",
        "mode = ap.parse_args().mode"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMSgjuiqrtn1",
        "outputId": "f288c625-5598-4fac-9ee4-4d8fb67d3535"
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    \"\"\"\n",
        "    Plot Accuracy and Loss curves given the model_history\n",
        "    \"\"\"\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    fig.savefig('plot.png')\n",
        "    plt.show()\n",
        "\n",
        "# Define data generators\n",
        "train_dir = 'data/train'\n",
        "val_dir = 'data/test'\n",
        "\n",
        "num_train = 28709\n",
        "num_val = 7178\n",
        "batch_size = 64\n",
        "num_epoch = 50\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(48,48),\n",
        "        batch_size=batch_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(48,48),\n",
        "        batch_size=batch_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "# If you want to train the same model or try other models, go for this\n",
        "if mode == \"train\":\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
        "    model_info = model.fit_generator(\n",
        "            train_generator,\n",
        "            steps_per_epoch=num_train // batch_size,\n",
        "            epochs=num_epoch,\n",
        "            validation_data=validation_generator,\n",
        "            validation_steps=num_val // batch_size)\n",
        "    plot_model_history(model_info)\n",
        "    model.save_weights('model.h5')\n",
        "\n",
        "# emotions will be displayed on your face from the webcam feed\n",
        "elif mode == \"display\":\n",
        "    model.load_weights('model.h5')\n",
        "\n",
        "    # prevents openCL usage and unnecessary logging messages\n",
        "    cv2.ocl.setUseOpenCL(False)\n",
        "\n",
        "    # dictionary which assigns each label an emotion (alphabetical order)\n",
        "    emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
        "\n",
        "    # start the webcam feed\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    while True:\n",
        "        # Find haar cascade to draw bounding box around face\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        facecasc = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = facecasc.detectMultiScale(gray,scaleFactor=1.3, minNeighbors=5)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
        "            roi_gray = gray[y:y + h, x:x + w]\n",
        "            cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
        "            prediction = model.predict(cropped_img)\n",
        "            maxindex = int(np.argmax(prediction))\n",
        "            cv2.putText(frame, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        cv2.imshow('Video', cv2.resize(frame,(1600,960),interpolation = cv2.INTER_CUBIC))\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Tz-F0hstbx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}